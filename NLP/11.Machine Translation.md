# Machine Translation

### Indice degli argomenti

---

## Machine Translation

[~ Vai all'indice](#indice-degli-argomenti)

**Definizione:** La **machine translation** (traduzione automatica) è il processo di traduzione di testi da una lingua
all'altra utilizzando software o algoritmi automatizzati. Questo task coinvolge la conversione di un testo scritto in
una lingua di origine in un testo equivalente in una lingua di destinazione.

**Funzionamento:** La machine translation può essere realizzata attraverso due principali approcci:

- **Statistico:** In questo approccio, il sistema di traduzione automatica si basa su modelli statistici che utilizzano
  frequenze e probabilità per associare parole e frasi nelle due lingue. Questo metodo ha perso popolarità con l'avvento
  delle reti neurali.

- **Neurale:** Il metodo di traduzione automatica neurale utilizza reti neurali profonde per apprendere direttamente
  dalle coppie di frasi tradotte, catturando relazioni complesse tra le lingue. Questo approccio ha dimostrato
  prestazioni eccezionali negli ultimi anni.

**Applicazioni:** La machine translation ha numerose applicazioni, tra cui:

- Traduzione di documenti e testi commerciali.
- Traduzione in tempo reale di conversazioni durante videoconferenze o chat online.
- Traduzione di contenuti web e pagine internet.
- Localizzazione di software e applicazioni.
- Sottotitolazione e traduzione automatica di video e programmi televisivi.
- Traduzione di testi medici e scientifici.

---

## Apprendimento tramite Testi Paralleli

[~ Vai all'indice](#indice-degli-argomenti)

**Funzionamento:** L'apprendimento tramite testi paralleli è un metodo utilizzato nell'ambito della machine translation
e del Natural Language Processing (NLP) per allenare modelli di traduzione automatica. Ecco come funziona:

1. **Raccolta di testi paralleli:** Inizialmente, è necessario raccogliere una vasta quantità di testi che sono
   disponibili in due o più lingue diverse. Questi testi dovrebbero avere una corrispondenza significativa tra le
   lingue, il che significa che le frasi o le porzioni di testo in una lingua devono essere traducibili in modo coerente
   nell'altra lingua.

2. **Allineamento dei testi:** Il passo successivo è l'allineamento dei testi paralleli. Questo processo consiste nel
   creare coppie di frasi o segmenti di testo che sono equivalenti tra le lingue di origine e di destinazione. Ad
   esempio, se si ha un testo in italiano e la sua traduzione in inglese, si creano coppie di frasi corrispondenti tra
   le due lingue.

3. **Allenamento del modello:** Una volta che si dispongono di testi paralleli allineati, è possibile utilizzarli per
   allenare il modello di traduzione automatica. Il modello può essere basato su approcci statistici o neurali, ma negli
   ultimi anni, i modelli neurali, come le reti neurali profonde, hanno dimostrato di essere particolarmente efficaci
   per questo compito.

4. **Ottimizzazione del modello:** Durante il processo di allenamento, il modello cerca di apprendere le relazioni tra
   le frasi nelle diverse lingue per tradurle in modo accurato. Questo comporta l'ottimizzazione dei parametri del
   modello attraverso l'analisi dei dati di allenamento e l'aggiustamento di pesi e parametri per minimizzare l'errore
   di traduzione.

5. **Valutazione e affinamento:** Dopo l'allenamento iniziale, il modello viene valutato utilizzando dati di test
   separati per misurare la sua capacità di traduzione. Se necessario, il modello può essere ulteriormente affinato o
   ottimizzato per migliorare le prestazioni.

L'apprendimento tramite testi paralleli è un metodo potente per creare sistemi di traduzione automatica, poiché consente
al modello di apprendere direttamente dalla comparazione tra le lingue. Tuttavia, è importante disporre di un ampio e di
alta qualità dataset di testi paralleli per ottenere risultati accurati e coerenti nella traduzione automatica.

### Dataset utilizzati per addestrare modelli di machine translation

Ci sono diversi dataset noti utilizzati per addestrare modelli di traduzione automatica e altri modelli relativi al
NLP (Natural Language Processing). Ecco alcuni dei dataset più famosi per questo tipo di task:

1. **WMT (Workshop on Machine Translation):** Questo è uno dei dataset più noti per la traduzione automatica. Ogni anno,
   il workshop rilascia dataset contenenti testi paralleli in diverse lingue. I dati includono spesso testi tratti da
   fonti come articoli di giornale, siti web, e altro ancora.

2. **Europarl:** Questo dataset contiene discorsi pronunciati nel Parlamento europeo in molte lingue europee. È spesso
   utilizzato come dataset di riferimento per la traduzione automatica.

3. **OpenSubtitles:** Contiene sottotitoli di film e programmi TV in diverse lingue. Questo dataset è ampiamente
   utilizzato per l'allenamento di modelli di traduzione automatica.

4. **TED Talks:** Questo dataset contiene trascrizioni di discorsi TED in diverse lingue. È spesso utilizzato per
   l'allenamento di modelli di traduzione automatica e per task di sintesi vocale.

5. **Common Crawl:** Contiene testi estratti da pagine web in molte lingue. È un dataset molto grande e diversificato
   utilizzato per vari task di NLP, inclusa la traduzione automatica.

6. **MultiUN (UN Corpus):** Questo dataset contiene traduzioni di documenti delle Nazioni Unite in molte lingue. È
   utilizzato
   principalmente per la traduzione automatica a fini di cooperazione internazionale.

7. **ParaCrawl:** È un dataset che raccoglie testi estratti da pagine web multilingue. È stato creato per migliorare la
   disponibilità di dati per la traduzione automatica.

8. **IWSLT (International Workshop on Spoken Language Translation):** Questo workshop rilascia dataset di traduzione
   automatica incentrati sulla traduzione di lingua parlata. È utilizzato per task di traduzione di conversazioni e
   discorsi.

9. **Tatoeba:** Una collezione collaborativa di frasi in diverse lingue, spesso con traduzioni. È utilizzato per scopi
   educativi e per l'allenamento di modelli di traduzione automatica.

10. **WikiMatrix:** Estratto da Wikipedia, questo dataset contiene coppie di frasi che sono state allineate tra diverse
    lingue. È ampiamente utilizzato per la traduzione automatica basata su modelli neurali.

Questi sono solo alcuni degli esempi di dataset utilizzati per l'allenamento di modelli di traduzione automatica. La
scelta del dataset dipende spesso dalla lingua di interesse e dalla specifica applicazione. È importante selezionare un
dataset di alta qualità e rappresentativo per ottenere risultati accurati nella traduzione automatica.

---

## Valutazione

[~ Vai all'indice](#indice-degli-argomenti)

Il processo di valutazione dei sistemi di traduzione automatica è fondamentale per misurare la qualità delle traduzioni
prodotte dai modelli. Una delle metriche più comuni utilizzate per valutare la qualità delle traduzioni è la BLEU (
Bilingual Evaluation Understudy). Ecco come funziona il processo di valutazione e cosa rappresenta la BLEU:

**Processo di valutazione:**

1. **Creazione di un set di riferimento:** Per valutare la qualità delle traduzioni, è necessario disporre di un set di
   testo di riferimento (o "gold standard") che contiene traduzioni umane di testi di origine. Questo set di riferimento
   viene creato manualmente e rappresenta la traduzione di alta qualità che si desidera valutare.

2. **Generazione di traduzioni:** Il sistema di traduzione automatica (ad esempio, un modello neurale) genera traduzioni
   per gli stessi testi di origine presenti nel set di riferimento.

3. **Calcolo della metrica:** La metrica BLEU viene quindi utilizzata per confrontare le traduzioni generate dal sistema
   con le traduzioni umane di riferimento. La BLEU confronta le frasi nel testo generato con le frasi nel testo di
   riferimento e assegna un punteggio di similitudine basato su varie misurazioni.

**BLEU (Bilingual Evaluation Understudy):**
La BLEU è una delle metriche più comunemente utilizzate per la valutazione automatica delle traduzioni. Questa metrica
tiene conto della precisione delle traduzioni rispetto al set di riferimento. Ecco come funziona la BLEU:

1. **N-gram overlap:** La BLEU calcola la precisione dell'overlap degli n-grammi (sequenze di n parole consecutive) tra
   le traduzioni generate e il testo di riferimento. Questo significa che valuta quanto le parole e le sequenze di
   parole nel testo generato corrispondono a quelle nel testo di riferimento.

2. **Ponderazione n-gram:** La BLEU assegna punteggi più alti a traduzioni che corrispondono a n-grammi più lunghi, in
   modo da incoraggiare traduzioni più fluide e coerenti.

3. **Brevità della traduzione:** Per evitare traduzioni troppo corte, la BLEU tiene conto della brevità della traduzione
   rispetto al testo di riferimento.

4. **Normalizzazione:** La BLEU normalizza il punteggio finale in modo da ottenere un valore compreso tra 0 e 1, dove 1
   rappresenta una corrispondenza perfetta tra la traduzione generata e il testo di riferimento.

In generale, un punteggio BLEU più alto indica una migliore corrispondenza tra la traduzione automatica e il testo di
riferimento. Tuttavia, va notato che la BLEU ha alcune limitazioni, come la mancanza di sensibilità alla coerenza
semantica e alla fluidità delle traduzioni. Pertanto, è spesso utilizzata insieme ad altre metriche per ottenere una
valutazione più completa delle traduzioni automatiche.

### BLEU

**Spiegazione Formale:**
La BLEU è una metrica di valutazione automatica utilizzata per misurare la qualità delle traduzioni automatiche in base
alla loro similitudine con le traduzioni umane di riferimento. La formula della BLEU è la seguente:

```text
BLEU = BP * exp(∑(n=1 to N) w_n * log(p_n))
```

Dove:

- `BP` è il fattore di penalizzazione per la brevità della traduzione (Brevity Penalty).
- `N` è il numero massimo di n-grammi considerati (solitamente 4).
- `w_n` sono i pesi assegnati a ciascun n-gramma (solitamente tutti impostati a 0.25).
- `p_n` è la precisione dell'n-gramma.

La precisione dell'n-gramma `p_n` è calcolata come il numero di n-grammi corrispondenti tra la traduzione generata e il
testo di riferimento, diviso per il numero totale di n-grammi nella traduzione generata. In altre parole, misura quanto
le sequenze di parole nella traduzione generata corrispondono a quelle nel testo di riferimento per vari valori di n.

**Spiegazione Sintetica:**
La BLEU è una metrica che aiuta a valutare la qualità delle traduzioni automatiche. Funziona confrontando la traduzione
generata da un computer con traduzioni fatte da persone. Ecco come funziona in parole semplici:

1. Guarda quanto le parole e le frasi nella traduzione automatica sono simili a quelle nelle traduzioni umane di
   riferimento.

2. Dà punteggi più alti se le traduzioni hanno frasi lunghe e simili alle traduzioni umane.

3. Controlla che la traduzione non sia troppo breve rispetto alle traduzioni di riferimento.

4. Calcola un punteggio finale che ti dice quanto la traduzione automatica sia simile alle traduzioni umane. Un
   punteggio più alto è migliore.

In breve, la BLEU aiuta a capire quanto bene un computer può tradurre rispetto alle persone, usando una formula che
guarda le parole, le frasi e la lunghezza della traduzione.

### Precisione n-gramma `p_n`

**Spiegazione Formale:**
La precisione dell'n-gramma `p_n` è una parte importante della formula BLEU. Essa misura quanto le sequenze di n parole
consecutive nella traduzione generata corrispondono alle sequenze di n parole consecutive nei testi di riferimento
forniti da esseri umani. La formula per calcolare la precisione dell'n-gramma `p_n` è la seguente:

```text
p_n = (Numero di n-grammi corrispondenti tra la traduzione generata e il testo di riferimento) / (Numero totale di
n-grammi nella traduzione generata)
```

In altre parole, `p_n` conta quanti frammenti di n parole consecutivi nella traduzione generata coincidono con quelli
nei testi di riferimento e divide questo numero per il totale di frammenti di n parole consecutivi nella traduzione
generata. Questo calcolo misura quanto le parti della traduzione generata sono simili alle parti dei testi di
riferimento per un dato valore di n.

**Spiegazione Sintetica:**
La precisione dell'n-gramma `p_n` è una parte della BLEU che guarda quanto le frasi nella traduzione sono simili a
quelle nei testi di riferimento. Si fa contando quanti pezzi di n parole consecutive corrispondono tra la traduzione
generata e i testi di riferimento e dividendo questo numero per il totale di pezzi di n parole consecutive nella
traduzione generata. Questo ci dice quanto le parti della traduzione sono simili alle parti dei testi di riferimento per
una determinata lunghezza di n parole consecutive.

### Brevity penalty `BP`

**Spiegazione Formale:**
Il "Brevity Penalty" è un componente della formula BLEU che viene utilizzato per penalizzare le traduzioni generiche che
sono significativamente più corte dei testi di riferimento. Questo è importante perché una traduzione troppo breve
potrebbe ottenere un punteggio elevato di precisione n-gramma senza rappresentare efficacemente il contenuto del testo
originale. La formula per calcolare il "Brevity Penalty" è la seguente:

```text
Brevity Penalty = min(1, (Lunghezza della traduzione generata / Lunghezza del testo di riferimento più breve))^B
```

Dove:

- "Lunghezza della traduzione generata" è il numero di parole nella traduzione generata.
- "Lunghezza del testo di riferimento più breve" è la lunghezza del testo di riferimento più corto tra quelli forniti.
- "B" è un esponente, spesso impostato a 0.25.

In poche parole, il "Brevity Penalty" assicura che la lunghezza della traduzione generata sia confrontata con la
lunghezza del testo di riferimento più breve e applica una penalità se la traduzione generata è troppo breve rispetto a
questo riferimento.

**Spiegazione Sintetica:**
Il "Brevity Penalty" è un modo per penalizzare le traduzioni troppo brevi. Se una traduzione è molto più corta dei testi
di riferimento, otterrà una penalità. Questo aiuta a evitare che le traduzioni troppo corte ottengano punteggi elevati
nella valutazione BLEU.

---

## Statistical MT

[~ Vai all'indice](#indice-degli-argomenti)

**Spiegazione Formale:**
La "Statistical Machine Translation" (Traduzione Automatica Statistica) è un paradigma di traduzione automatica basato
su modelli statistici. Questi modelli utilizzano statistiche e probabilità per apprendere come tradurre da una lingua di
origine a una lingua di destinazione. Il processo di SMT coinvolge la raccolta di enormi quantità di testi paralleli,
ovvero testi in cui la stessa informazione è espressa in due lingue diverse. I modelli statistici utilizzano queste
coppie di testi per stimare la probabilità di traduzione di parole, frasi o strutture linguistiche da una lingua
all'altra. Tra le tecniche comuni utilizzate nella SMT ci sono i modelli di linguaggio, i modelli di traduzione e
l'allineamento di frasi.

**Spiegazione Sintetica:**
La "Statistical Machine Translation" è un modo sofisticato di far tradurre automaticamente testi da una lingua a
un'altra. Funziona imparando dalle traduzioni esistenti in due lingue diverse e usando matematica per capire come
tradurre parole e frasi. In breve, è come insegnare a un computer a tradurre guardando molte traduzioni già fatte.

### Noisy channel

**Spiegazione Formale:**
Il concetto di "noisy channel" (canale rumoroso) è una parte fondamentale della teoria dell'Information Theory e viene
spesso utilizzato in contesti di elaborazione del linguaggio naturale, compresa la traduzione automatica. In un contesto
di traduzione automatica, il "noisy channel" è un modello probabilistico che rappresenta l'idea che una sequenza di
parole in una lingua di origine è stata "corrotta" in qualche modo durante la traduzione in una lingua di destinazione.

Matematicamente, il modello del "noisy channel" può essere rappresentato utilizzando la formula di Bayes:

![img.png](assets/noisy_channel.png)

Dove:

- P(frase di origine | frase di destinazione) rappresenta la probabilità che la frase di origine sia
  stata tradotta nella frase di destinazione.
- P(frase di destinazione | frase di origine) è la probabilità di ottenere la frase di destinazione
  data la frase di origine, detta anche "modello di traduzione".
- P(frase di origine) è la probabilità a priori della frase di origine.
- P(frase di destinazione) è la probabilità a priori della frase di destinazione.

Il "canale rumoroso" rappresenta il processo attraverso il quale la traduzione dalla lingua di origine alla lingua di
destinazione introduce "rumore" o errori nel testo tradotto.

**Spiegazione Sintetica:**
Il concetto di "noisy channel" è come un modello matematico che ci aiuta a capire come le parole o le frasi possono
essere tradotte con errori o rumore quando passano da una lingua all'altra. È come se ci fosse un canale rumoroso che fa
sì che le traduzioni non siano sempre perfette. Questo concetto è molto utile nella traduzione automatica e
nell'elaborazione del linguaggio naturale.

_Continuare da pagina 9._

---